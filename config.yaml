data:
  MPII:                                         # refer http://human-pose.mpi-inf.mpg.de/#download
    paths:
      base: data/MPII                           # dir path; can be absolute path
      images: images                            # dir path; must be relative to base path
      annotations:
        training: annotations/train.h5          # file path; must be relative to base path
        validation: annotations/valid.h5        # file path; must be relative to base path
        testing: annotations/test.h5            # file path; must be relative to base path

    reference_image_size: 200   # Reference size of Person's image in pixels. MPII dataset stores the scale with reference to `200 pixel` size.
    parts:                      # parts (a.k.a. keypoints) on annotated on the body of a person.
      max_count: 16             # max. keypoints on person's body in MPII dataset
      names:       [rank, rkne, rhip, lhip, lkne, lank, pelv, thrx, neck, head, rwri, relb, rsho, lsho, lelb, lwri]   # order is important
      ids:         [   0,    1,    2,     3,   4,    5,    6,    7,    8,    9,   10,   11,   12,   13,   14,   15]   # corresponding part ids
      flipped_ids: [   5,    4,    3,     2,   1,    0,    6,    7,    8,    9,   15,   14,   13,   12,   11,   10]   # corresponding flipped part ids (right becomes left)
    part_pairs:                                                                                   # connecting two keypoints on the human body to form a link/edge on the body
      names: [ ankle,   knee,    hip, pelvis, thorax, neck, head,    wrist,    elbow, shoulder]   # name of keypoints-names forming a link
      ids:   [[0, 5], [1, 4], [2, 3],    [6],    [7],   [8], [9], [10, 15], [11, 14], [12, 13]]   # pair of keypoint-ids forming a link


neural_network:
  PoseNet:
    n_hourglass: 8
    in_channels: 256
    out_channels: 16
    channel_increase: 0

  train:
    random_seed: 1234
    batch_size: 16
    input_resolution: 256
    output_resolution: 64
    num_workers: 2
    train_iterations: 1000                     # training iterations
    valid_iterations: 10                       # validation iterations
    learning_rate: 1e-3
    max_num_people: 1
    decay_iters: 100000
    decay_lr: 2e-4
    use_data_loader: True
    data_augmentation:
      rotation_angle_max: 30                   # max. rotation angle in degrees
      image_scale_factor:
        min: 0.75
        max: 1.75
      image_color_jitter_probability: 0.5     # probability to introduce random color jitter in image
      image_horizontal_flip_probability: 0.5  # probability to flip image horizontally.
      hue_max_delta: 0.2                      # max possible change in hue of image between [0, 0.5]
      saturation_min_delta: 0.5               # minimum possible change in saturation of image
      brightness_max_delta: 0.3               # max possible change in image brightness
      contrast_min_delta: 0.5                 # minimum possible change in contrast of image
    DistributedDataParallel:
      use: True                               # if ``True``, use DistributedDataParallel from pytorch.
      backend: gloo                           # for more options refer https://pytorch.org/docs/stable/distributed.html#torch.distributed.init_process_group
      MASTER_ADDR: 127.0.0.1                  # ip address to use
      MASTER_PORT: 12355                      # port number to use
      world_size: 1                           # default 1. Change it depending on your requirements

  inference:
    keys: [imgs]
    num_eval: 2958                            # number of val examples used. entire set is 2958
    train_num_eval: 300                       # number of train examples tested at test time
