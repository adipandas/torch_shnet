{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "sys.path.insert(0, \"../utils/\")\n",
    "sys.path.insert(0, \"../\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_show(image, figsize=(7, 7)):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(image, interpolation='nearest')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def image_keypoints_show(image_tensor, keypoints, figsize=(7, 7), resize=True):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    img = image_tensor.numpy().transpose((1, 2, 0))\n",
    "    \n",
    "    if resize:\n",
    "        img = cv2.resize(img, (64, 64))\n",
    "    \n",
    "    ax.imshow(img, interpolation='nearest')\n",
    "\n",
    "    for i in range(keypoints.shape[1]):\n",
    "        kp = keypoints[0, i, :]\n",
    "        if kp[0]>0:\n",
    "            ax.plot(kp[0], kp[1], marker='o', color=\"blue\", markersize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def image_grid_show(image_stack, figsize=(12, 12)):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                     nrows_ncols=(4, 4),  # creates 2x2 grid of axes\n",
    "                     axes_pad=0.1,  # pad between axes in inch.\n",
    "                    )\n",
    "    stack_indices = [i for i in range(image_stack.shape[0])]\n",
    "    for ax, im_idx in zip(grid, stack_indices):\n",
    "        ax.imshow(image_stack[im_idx])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration file parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.read_config import yaml_to_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml_to_object(\"./../config.yaml\")\n",
    "\n",
    "root_dir = osp.abspath(osp.dirname(\".\"))\n",
    "\n",
    "setattr(config, \"root_dir\", osp.dirname(root_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPIIAnnotationHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.annotation_handler import MPIIAnnotationHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = osp.join(config.root_dir, config.data.MPII.path.base)\n",
    "training_annotation_file = osp.join(data_path, config.data.MPII.path.annotations.training)\n",
    "validation_annotation_file = osp.join(data_path, config.data.MPII.path.annotations.validation)\n",
    "image_dir = osp.join(data_path, config.data.MPII.path.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh = MPIIAnnotationHandler(training_annotation_file, validation_annotation_file, image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path, keypoints, center, scale = dh[0]\n",
    "print(f\"image_path: {image_path}\")\n",
    "print(f\"center: {center}\")\n",
    "print(f\"scale: {scale}\\n\")\n",
    "print(f\"keypoints:\\n{keypoints}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, valid_indices = dh.split_data()\n",
    "print(f\"train_indices.shape: {train_indices.shape}\")\n",
    "print(f\"valid_indices.shape: {valid_indices.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPIIDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataset import MPIIDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MPIIDataset(\n",
    "    indices=train_indices,\n",
    "    mpii_annotation_handle=dh,\n",
    "    horizontally_flipped_keypoint_ids=config.data.MPII.parts.flipped_ids,\n",
    "    input_resolution=config.neural_network.train.input_resolution,\n",
    "    output_resolution=config.neural_network.train.output_resolution,\n",
    "    num_parts=config.data.MPII.parts.max_count,\n",
    "    reference_image_size=config.data.MPII.reference_image_size,\n",
    "    max_rotation_angle=config.neural_network.train.data_augmentation.rotation_angle_max,\n",
    "    image_scale_factor_range=(config.neural_network.train.data_augmentation.image_scale_factor.min, config.neural_network.train.data_augmentation.image_scale_factor.max),\n",
    "    image_color_jitter_probability=config.neural_network.train.data_augmentation.image_color_jitter_probability,\n",
    "    image_horizontal_flip_probability=config.neural_network.train.data_augmentation.image_horizontal_flip_probability,\n",
    "    hue_max_delta=config.neural_network.train.data_augmentation.hue_max_delta,\n",
    "    saturation_min_delta=config.neural_network.train.data_augmentation.saturation_min_delta,\n",
    "    brightness_max_delta=config.neural_network.train.data_augmentation.brightness_max_delta,\n",
    "    contrast_min_delta=config.neural_network.train.data_augmentation.contrast_min_delta,\n",
    ")\n",
    "\n",
    "valid_dataset = MPIIDataset(\n",
    "    indices=valid_indices,\n",
    "    mpii_annotation_handle=dh,\n",
    "    horizontally_flipped_keypoint_ids=config.data.MPII.parts.flipped_ids,\n",
    "    input_resolution=config.neural_network.train.input_resolution,\n",
    "    output_resolution=config.neural_network.train.output_resolution,\n",
    "    num_parts=config.data.MPII.parts.max_count,\n",
    "    reference_image_size=config.data.MPII.reference_image_size,\n",
    "    max_rotation_angle=config.neural_network.train.data_augmentation.rotation_angle_max,\n",
    "    image_scale_factor_range=(config.neural_network.train.data_augmentation.image_scale_factor.min, config.neural_network.train.data_augmentation.image_scale_factor.max),\n",
    "    image_color_jitter_probability=config.neural_network.train.data_augmentation.image_color_jitter_probability,\n",
    "    image_horizontal_flip_probability=config.neural_network.train.data_augmentation.image_horizontal_flip_probability,\n",
    "    hue_max_delta=config.neural_network.train.data_augmentation.hue_max_delta,\n",
    "    saturation_min_delta=config.neural_network.train.data_augmentation.saturation_min_delta,\n",
    "    brightness_max_delta=config.neural_network.train.data_augmentation.brightness_max_delta,\n",
    "    contrast_min_delta=config.neural_network.train.data_augmentation.contrast_min_delta\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idxs = np.random.randint(0, 6000, size=(100,))\n",
    "for idx in idxs:\n",
    "    image_tensor, heatmap, in_kps, out_kps = train_dataset[idx]\n",
    "    \n",
    "    print(f\"image_tensor.shape: {image_tensor.shape}\")\n",
    "    print(f\"heatmap.shape: {heatmap.shape}\")\n",
    "    \n",
    "    image_keypoints_show(image_tensor, out_kps, figsize=(3, 3))\n",
    "    image_show(torch.sum(heatmap, axis=0).numpy(), figsize=(3, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
